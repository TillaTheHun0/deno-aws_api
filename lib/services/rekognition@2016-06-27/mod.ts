// Autogenerated API client for: Amazon Rekognition

import type { ServiceClient, ApiFactory, ApiMetadata } from '../../client/common.ts';
interface RequestConfig {
  abortSignal?: AbortSignal;
}

import * as cmnP from "../../encoding/common.ts";
import * as jsonP from "../../encoding/json.ts";

export default class Rekognition {
  #client: ServiceClient;
  constructor(apiFactory: ApiFactory) {
    this.#client = apiFactory.buildServiceClient(Rekognition.ApiMetadata);
  }

  static ApiMetadata: ApiMetadata = {
    "apiVersion": "2016-06-27",
    "endpointPrefix": "rekognition",
    "jsonVersion": "1.1",
    "protocol": "json",
    "serviceFullName": "Amazon Rekognition",
    "serviceId": "Rekognition",
    "signatureVersion": "v4",
    "targetPrefix": "RekognitionService",
    "uid": "rekognition-2016-06-27"
  };

  async compareFaces(
    {abortSignal, ...params}: RequestConfig & CompareFacesRequest,
  ): Promise<CompareFacesResponse> {
    const body: jsonP.JSONObject = {
      SourceImage: fromImage(params["SourceImage"]),
      TargetImage: fromImage(params["TargetImage"]),
      SimilarityThreshold: params["SimilarityThreshold"],
      QualityFilter: params["QualityFilter"],
    };
    const resp = await this.#client.performRequest({
      abortSignal, body,
      action: "CompareFaces",
    });
    return jsonP.readObj({
      required: {},
      optional: {
        "SourceImageFace": toComparedSourceImageFace,
        "FaceMatches": [toCompareFacesMatch],
        "UnmatchedFaces": [toComparedFace],
        "SourceImageOrientationCorrection": (x: jsonP.JSONValue) => cmnP.readEnum<OrientationCorrection>(x),
        "TargetImageOrientationCorrection": (x: jsonP.JSONValue) => cmnP.readEnum<OrientationCorrection>(x),
      },
    }, await resp.json());
  }

  async createCollection(
    {abortSignal, ...params}: RequestConfig & CreateCollectionRequest,
  ): Promise<CreateCollectionResponse> {
    const body: jsonP.JSONObject = {
      CollectionId: params["CollectionId"],
    };
    const resp = await this.#client.performRequest({
      abortSignal, body,
      action: "CreateCollection",
    });
    return jsonP.readObj({
      required: {},
      optional: {
        "StatusCode": "n",
        "CollectionArn": "s",
        "FaceModelVersion": "s",
      },
    }, await resp.json());
  }

  async createProject(
    {abortSignal, ...params}: RequestConfig & CreateProjectRequest,
  ): Promise<CreateProjectResponse> {
    const body: jsonP.JSONObject = {
      ProjectName: params["ProjectName"],
    };
    const resp = await this.#client.performRequest({
      abortSignal, body,
      action: "CreateProject",
    });
    return jsonP.readObj({
      required: {},
      optional: {
        "ProjectArn": "s",
      },
    }, await resp.json());
  }

  async createProjectVersion(
    {abortSignal, ...params}: RequestConfig & CreateProjectVersionRequest,
  ): Promise<CreateProjectVersionResponse> {
    const body: jsonP.JSONObject = {
      ProjectArn: params["ProjectArn"],
      VersionName: params["VersionName"],
      OutputConfig: fromOutputConfig(params["OutputConfig"]),
      TrainingData: fromTrainingData(params["TrainingData"]),
      TestingData: fromTestingData(params["TestingData"]),
    };
    const resp = await this.#client.performRequest({
      abortSignal, body,
      action: "CreateProjectVersion",
    });
    return jsonP.readObj({
      required: {},
      optional: {
        "ProjectVersionArn": "s",
      },
    }, await resp.json());
  }

  async createStreamProcessor(
    {abortSignal, ...params}: RequestConfig & CreateStreamProcessorRequest,
  ): Promise<CreateStreamProcessorResponse> {
    const body: jsonP.JSONObject = {
      Input: fromStreamProcessorInput(params["Input"]),
      Output: fromStreamProcessorOutput(params["Output"]),
      Name: params["Name"],
      Settings: fromStreamProcessorSettings(params["Settings"]),
      RoleArn: params["RoleArn"],
    };
    const resp = await this.#client.performRequest({
      abortSignal, body,
      action: "CreateStreamProcessor",
    });
    return jsonP.readObj({
      required: {},
      optional: {
        "StreamProcessorArn": "s",
      },
    }, await resp.json());
  }

  async deleteCollection(
    {abortSignal, ...params}: RequestConfig & DeleteCollectionRequest,
  ): Promise<DeleteCollectionResponse> {
    const body: jsonP.JSONObject = {
      CollectionId: params["CollectionId"],
    };
    const resp = await this.#client.performRequest({
      abortSignal, body,
      action: "DeleteCollection",
    });
    return jsonP.readObj({
      required: {},
      optional: {
        "StatusCode": "n",
      },
    }, await resp.json());
  }

  async deleteFaces(
    {abortSignal, ...params}: RequestConfig & DeleteFacesRequest,
  ): Promise<DeleteFacesResponse> {
    const body: jsonP.JSONObject = {
      CollectionId: params["CollectionId"],
      FaceIds: params["FaceIds"],
    };
    const resp = await this.#client.performRequest({
      abortSignal, body,
      action: "DeleteFaces",
    });
    return jsonP.readObj({
      required: {},
      optional: {
        "DeletedFaces": ["s"],
      },
    }, await resp.json());
  }

  async deleteProject(
    {abortSignal, ...params}: RequestConfig & DeleteProjectRequest,
  ): Promise<DeleteProjectResponse> {
    const body: jsonP.JSONObject = {
      ProjectArn: params["ProjectArn"],
    };
    const resp = await this.#client.performRequest({
      abortSignal, body,
      action: "DeleteProject",
    });
    return jsonP.readObj({
      required: {},
      optional: {
        "Status": (x: jsonP.JSONValue) => cmnP.readEnum<ProjectStatus>(x),
      },
    }, await resp.json());
  }

  async deleteProjectVersion(
    {abortSignal, ...params}: RequestConfig & DeleteProjectVersionRequest,
  ): Promise<DeleteProjectVersionResponse> {
    const body: jsonP.JSONObject = {
      ProjectVersionArn: params["ProjectVersionArn"],
    };
    const resp = await this.#client.performRequest({
      abortSignal, body,
      action: "DeleteProjectVersion",
    });
    return jsonP.readObj({
      required: {},
      optional: {
        "Status": (x: jsonP.JSONValue) => cmnP.readEnum<ProjectVersionStatus>(x),
      },
    }, await resp.json());
  }

  async deleteStreamProcessor(
    {abortSignal, ...params}: RequestConfig & DeleteStreamProcessorRequest,
  ): Promise<DeleteStreamProcessorResponse> {
    const body: jsonP.JSONObject = {
      Name: params["Name"],
    };
    const resp = await this.#client.performRequest({
      abortSignal, body,
      action: "DeleteStreamProcessor",
    });
    return jsonP.readObj({
      required: {},
      optional: {},
    }, await resp.json());
  }

  async describeCollection(
    {abortSignal, ...params}: RequestConfig & DescribeCollectionRequest,
  ): Promise<DescribeCollectionResponse> {
    const body: jsonP.JSONObject = {
      CollectionId: params["CollectionId"],
    };
    const resp = await this.#client.performRequest({
      abortSignal, body,
      action: "DescribeCollection",
    });
    return jsonP.readObj({
      required: {},
      optional: {
        "FaceCount": "n",
        "FaceModelVersion": "s",
        "CollectionARN": "s",
        "CreationTimestamp": "d",
      },
    }, await resp.json());
  }

  async describeProjectVersions(
    {abortSignal, ...params}: RequestConfig & DescribeProjectVersionsRequest,
  ): Promise<DescribeProjectVersionsResponse> {
    const body: jsonP.JSONObject = {
      ProjectArn: params["ProjectArn"],
      VersionNames: params["VersionNames"],
      NextToken: params["NextToken"],
      MaxResults: params["MaxResults"],
    };
    const resp = await this.#client.performRequest({
      abortSignal, body,
      action: "DescribeProjectVersions",
    });
    return jsonP.readObj({
      required: {},
      optional: {
        "ProjectVersionDescriptions": [toProjectVersionDescription],
        "NextToken": "s",
      },
    }, await resp.json());
  }

  async describeProjects(
    {abortSignal, ...params}: RequestConfig & DescribeProjectsRequest = {},
  ): Promise<DescribeProjectsResponse> {
    const body: jsonP.JSONObject = {
      NextToken: params["NextToken"],
      MaxResults: params["MaxResults"],
    };
    const resp = await this.#client.performRequest({
      abortSignal, body,
      action: "DescribeProjects",
    });
    return jsonP.readObj({
      required: {},
      optional: {
        "ProjectDescriptions": [toProjectDescription],
        "NextToken": "s",
      },
    }, await resp.json());
  }

  async describeStreamProcessor(
    {abortSignal, ...params}: RequestConfig & DescribeStreamProcessorRequest,
  ): Promise<DescribeStreamProcessorResponse> {
    const body: jsonP.JSONObject = {
      Name: params["Name"],
    };
    const resp = await this.#client.performRequest({
      abortSignal, body,
      action: "DescribeStreamProcessor",
    });
    return jsonP.readObj({
      required: {},
      optional: {
        "Name": "s",
        "StreamProcessorArn": "s",
        "Status": (x: jsonP.JSONValue) => cmnP.readEnum<StreamProcessorStatus>(x),
        "StatusMessage": "s",
        "CreationTimestamp": "d",
        "LastUpdateTimestamp": "d",
        "Input": toStreamProcessorInput,
        "Output": toStreamProcessorOutput,
        "RoleArn": "s",
        "Settings": toStreamProcessorSettings,
      },
    }, await resp.json());
  }

  async detectCustomLabels(
    {abortSignal, ...params}: RequestConfig & DetectCustomLabelsRequest,
  ): Promise<DetectCustomLabelsResponse> {
    const body: jsonP.JSONObject = {
      ProjectVersionArn: params["ProjectVersionArn"],
      Image: fromImage(params["Image"]),
      MaxResults: params["MaxResults"],
      MinConfidence: params["MinConfidence"],
    };
    const resp = await this.#client.performRequest({
      abortSignal, body,
      action: "DetectCustomLabels",
    });
    return jsonP.readObj({
      required: {},
      optional: {
        "CustomLabels": [toCustomLabel],
      },
    }, await resp.json());
  }

  async detectFaces(
    {abortSignal, ...params}: RequestConfig & DetectFacesRequest,
  ): Promise<DetectFacesResponse> {
    const body: jsonP.JSONObject = {
      Image: fromImage(params["Image"]),
      Attributes: params["Attributes"],
    };
    const resp = await this.#client.performRequest({
      abortSignal, body,
      action: "DetectFaces",
    });
    return jsonP.readObj({
      required: {},
      optional: {
        "FaceDetails": [toFaceDetail],
        "OrientationCorrection": (x: jsonP.JSONValue) => cmnP.readEnum<OrientationCorrection>(x),
      },
    }, await resp.json());
  }

  async detectLabels(
    {abortSignal, ...params}: RequestConfig & DetectLabelsRequest,
  ): Promise<DetectLabelsResponse> {
    const body: jsonP.JSONObject = {
      Image: fromImage(params["Image"]),
      MaxLabels: params["MaxLabels"],
      MinConfidence: params["MinConfidence"],
    };
    const resp = await this.#client.performRequest({
      abortSignal, body,
      action: "DetectLabels",
    });
    return jsonP.readObj({
      required: {},
      optional: {
        "Labels": [toLabel],
        "OrientationCorrection": (x: jsonP.JSONValue) => cmnP.readEnum<OrientationCorrection>(x),
        "LabelModelVersion": "s",
      },
    }, await resp.json());
  }

  async detectModerationLabels(
    {abortSignal, ...params}: RequestConfig & DetectModerationLabelsRequest,
  ): Promise<DetectModerationLabelsResponse> {
    const body: jsonP.JSONObject = {
      Image: fromImage(params["Image"]),
      MinConfidence: params["MinConfidence"],
      HumanLoopConfig: fromHumanLoopConfig(params["HumanLoopConfig"]),
    };
    const resp = await this.#client.performRequest({
      abortSignal, body,
      action: "DetectModerationLabels",
    });
    return jsonP.readObj({
      required: {},
      optional: {
        "ModerationLabels": [toModerationLabel],
        "ModerationModelVersion": "s",
        "HumanLoopActivationOutput": toHumanLoopActivationOutput,
      },
    }, await resp.json());
  }

  async detectProtectiveEquipment(
    {abortSignal, ...params}: RequestConfig & DetectProtectiveEquipmentRequest,
  ): Promise<DetectProtectiveEquipmentResponse> {
    const body: jsonP.JSONObject = {
      Image: fromImage(params["Image"]),
      SummarizationAttributes: fromProtectiveEquipmentSummarizationAttributes(params["SummarizationAttributes"]),
    };
    const resp = await this.#client.performRequest({
      abortSignal, body,
      action: "DetectProtectiveEquipment",
    });
    return jsonP.readObj({
      required: {},
      optional: {
        "ProtectiveEquipmentModelVersion": "s",
        "Persons": [toProtectiveEquipmentPerson],
        "Summary": toProtectiveEquipmentSummary,
      },
    }, await resp.json());
  }

  async detectText(
    {abortSignal, ...params}: RequestConfig & DetectTextRequest,
  ): Promise<DetectTextResponse> {
    const body: jsonP.JSONObject = {
      Image: fromImage(params["Image"]),
      Filters: fromDetectTextFilters(params["Filters"]),
    };
    const resp = await this.#client.performRequest({
      abortSignal, body,
      action: "DetectText",
    });
    return jsonP.readObj({
      required: {},
      optional: {
        "TextDetections": [toTextDetection],
        "TextModelVersion": "s",
      },
    }, await resp.json());
  }

  async getCelebrityInfo(
    {abortSignal, ...params}: RequestConfig & GetCelebrityInfoRequest,
  ): Promise<GetCelebrityInfoResponse> {
    const body: jsonP.JSONObject = {
      Id: params["Id"],
    };
    const resp = await this.#client.performRequest({
      abortSignal, body,
      action: "GetCelebrityInfo",
    });
    return jsonP.readObj({
      required: {},
      optional: {
        "Urls": ["s"],
        "Name": "s",
      },
    }, await resp.json());
  }

  async getCelebrityRecognition(
    {abortSignal, ...params}: RequestConfig & GetCelebrityRecognitionRequest,
  ): Promise<GetCelebrityRecognitionResponse> {
    const body: jsonP.JSONObject = {
      JobId: params["JobId"],
      MaxResults: params["MaxResults"],
      NextToken: params["NextToken"],
      SortBy: params["SortBy"],
    };
    const resp = await this.#client.performRequest({
      abortSignal, body,
      action: "GetCelebrityRecognition",
    });
    return jsonP.readObj({
      required: {},
      optional: {
        "JobStatus": (x: jsonP.JSONValue) => cmnP.readEnum<VideoJobStatus>(x),
        "StatusMessage": "s",
        "VideoMetadata": toVideoMetadata,
        "NextToken": "s",
        "Celebrities": [toCelebrityRecognition],
      },
    }, await resp.json());
  }

  async getContentModeration(
    {abortSignal, ...params}: RequestConfig & GetContentModerationRequest,
  ): Promise<GetContentModerationResponse> {
    const body: jsonP.JSONObject = {
      JobId: params["JobId"],
      MaxResults: params["MaxResults"],
      NextToken: params["NextToken"],
      SortBy: params["SortBy"],
    };
    const resp = await this.#client.performRequest({
      abortSignal, body,
      action: "GetContentModeration",
    });
    return jsonP.readObj({
      required: {},
      optional: {
        "JobStatus": (x: jsonP.JSONValue) => cmnP.readEnum<VideoJobStatus>(x),
        "StatusMessage": "s",
        "VideoMetadata": toVideoMetadata,
        "ModerationLabels": [toContentModerationDetection],
        "NextToken": "s",
        "ModerationModelVersion": "s",
      },
    }, await resp.json());
  }

  async getFaceDetection(
    {abortSignal, ...params}: RequestConfig & GetFaceDetectionRequest,
  ): Promise<GetFaceDetectionResponse> {
    const body: jsonP.JSONObject = {
      JobId: params["JobId"],
      MaxResults: params["MaxResults"],
      NextToken: params["NextToken"],
    };
    const resp = await this.#client.performRequest({
      abortSignal, body,
      action: "GetFaceDetection",
    });
    return jsonP.readObj({
      required: {},
      optional: {
        "JobStatus": (x: jsonP.JSONValue) => cmnP.readEnum<VideoJobStatus>(x),
        "StatusMessage": "s",
        "VideoMetadata": toVideoMetadata,
        "NextToken": "s",
        "Faces": [toFaceDetection],
      },
    }, await resp.json());
  }

  async getFaceSearch(
    {abortSignal, ...params}: RequestConfig & GetFaceSearchRequest,
  ): Promise<GetFaceSearchResponse> {
    const body: jsonP.JSONObject = {
      JobId: params["JobId"],
      MaxResults: params["MaxResults"],
      NextToken: params["NextToken"],
      SortBy: params["SortBy"],
    };
    const resp = await this.#client.performRequest({
      abortSignal, body,
      action: "GetFaceSearch",
    });
    return jsonP.readObj({
      required: {},
      optional: {
        "JobStatus": (x: jsonP.JSONValue) => cmnP.readEnum<VideoJobStatus>(x),
        "StatusMessage": "s",
        "NextToken": "s",
        "VideoMetadata": toVideoMetadata,
        "Persons": [toPersonMatch],
      },
    }, await resp.json());
  }

  async getLabelDetection(
    {abortSignal, ...params}: RequestConfig & GetLabelDetectionRequest,
  ): Promise<GetLabelDetectionResponse> {
    const body: jsonP.JSONObject = {
      JobId: params["JobId"],
      MaxResults: params["MaxResults"],
      NextToken: params["NextToken"],
      SortBy: params["SortBy"],
    };
    const resp = await this.#client.performRequest({
      abortSignal, body,
      action: "GetLabelDetection",
    });
    return jsonP.readObj({
      required: {},
      optional: {
        "JobStatus": (x: jsonP.JSONValue) => cmnP.readEnum<VideoJobStatus>(x),
        "StatusMessage": "s",
        "VideoMetadata": toVideoMetadata,
        "NextToken": "s",
        "Labels": [toLabelDetection],
        "LabelModelVersion": "s",
      },
    }, await resp.json());
  }

  async getPersonTracking(
    {abortSignal, ...params}: RequestConfig & GetPersonTrackingRequest,
  ): Promise<GetPersonTrackingResponse> {
    const body: jsonP.JSONObject = {
      JobId: params["JobId"],
      MaxResults: params["MaxResults"],
      NextToken: params["NextToken"],
      SortBy: params["SortBy"],
    };
    const resp = await this.#client.performRequest({
      abortSignal, body,
      action: "GetPersonTracking",
    });
    return jsonP.readObj({
      required: {},
      optional: {
        "JobStatus": (x: jsonP.JSONValue) => cmnP.readEnum<VideoJobStatus>(x),
        "StatusMessage": "s",
        "VideoMetadata": toVideoMetadata,
        "NextToken": "s",
        "Persons": [toPersonDetection],
      },
    }, await resp.json());
  }

  async getSegmentDetection(
    {abortSignal, ...params}: RequestConfig & GetSegmentDetectionRequest,
  ): Promise<GetSegmentDetectionResponse> {
    const body: jsonP.JSONObject = {
      JobId: params["JobId"],
      MaxResults: params["MaxResults"],
      NextToken: params["NextToken"],
    };
    const resp = await this.#client.performRequest({
      abortSignal, body,
      action: "GetSegmentDetection",
    });
    return jsonP.readObj({
      required: {},
      optional: {
        "JobStatus": (x: jsonP.JSONValue) => cmnP.readEnum<VideoJobStatus>(x),
        "StatusMessage": "s",
        "VideoMetadata": [toVideoMetadata],
        "AudioMetadata": [toAudioMetadata],
        "NextToken": "s",
        "Segments": [toSegmentDetection],
        "SelectedSegmentTypes": [toSegmentTypeInfo],
      },
    }, await resp.json());
  }

  async getTextDetection(
    {abortSignal, ...params}: RequestConfig & GetTextDetectionRequest,
  ): Promise<GetTextDetectionResponse> {
    const body: jsonP.JSONObject = {
      JobId: params["JobId"],
      MaxResults: params["MaxResults"],
      NextToken: params["NextToken"],
    };
    const resp = await this.#client.performRequest({
      abortSignal, body,
      action: "GetTextDetection",
    });
    return jsonP.readObj({
      required: {},
      optional: {
        "JobStatus": (x: jsonP.JSONValue) => cmnP.readEnum<VideoJobStatus>(x),
        "StatusMessage": "s",
        "VideoMetadata": toVideoMetadata,
        "TextDetections": [toTextDetectionResult],
        "NextToken": "s",
        "TextModelVersion": "s",
      },
    }, await resp.json());
  }

  async indexFaces(
    {abortSignal, ...params}: RequestConfig & IndexFacesRequest,
  ): Promise<IndexFacesResponse> {
    const body: jsonP.JSONObject = {
      CollectionId: params["CollectionId"],
      Image: fromImage(params["Image"]),
      ExternalImageId: params["ExternalImageId"],
      DetectionAttributes: params["DetectionAttributes"],
      MaxFaces: params["MaxFaces"],
      QualityFilter: params["QualityFilter"],
    };
    const resp = await this.#client.performRequest({
      abortSignal, body,
      action: "IndexFaces",
    });
    return jsonP.readObj({
      required: {},
      optional: {
        "FaceRecords": [toFaceRecord],
        "OrientationCorrection": (x: jsonP.JSONValue) => cmnP.readEnum<OrientationCorrection>(x),
        "FaceModelVersion": "s",
        "UnindexedFaces": [toUnindexedFace],
      },
    }, await resp.json());
  }

  async listCollections(
    {abortSignal, ...params}: RequestConfig & ListCollectionsRequest = {},
  ): Promise<ListCollectionsResponse> {
    const body: jsonP.JSONObject = {
      NextToken: params["NextToken"],
      MaxResults: params["MaxResults"],
    };
    const resp = await this.#client.performRequest({
      abortSignal, body,
      action: "ListCollections",
    });
    return jsonP.readObj({
      required: {},
      optional: {
        "CollectionIds": ["s"],
        "NextToken": "s",
        "FaceModelVersions": ["s"],
      },
    }, await resp.json());
  }

  async listFaces(
    {abortSignal, ...params}: RequestConfig & ListFacesRequest,
  ): Promise<ListFacesResponse> {
    const body: jsonP.JSONObject = {
      CollectionId: params["CollectionId"],
      NextToken: params["NextToken"],
      MaxResults: params["MaxResults"],
    };
    const resp = await this.#client.performRequest({
      abortSignal, body,
      action: "ListFaces",
    });
    return jsonP.readObj({
      required: {},
      optional: {
        "Faces": [toFace],
        "NextToken": "s",
        "FaceModelVersion": "s",
      },
    }, await resp.json());
  }

  async listStreamProcessors(
    {abortSignal, ...params}: RequestConfig & ListStreamProcessorsRequest = {},
  ): Promise<ListStreamProcessorsResponse> {
    const body: jsonP.JSONObject = {
      NextToken: params["NextToken"],
      MaxResults: params["MaxResults"],
    };
    const resp = await this.#client.performRequest({
      abortSignal, body,
      action: "ListStreamProcessors",
    });
    return jsonP.readObj({
      required: {},
      optional: {
        "NextToken": "s",
        "StreamProcessors": [toStreamProcessor],
      },
    }, await resp.json());
  }

  async recognizeCelebrities(
    {abortSignal, ...params}: RequestConfig & RecognizeCelebritiesRequest,
  ): Promise<RecognizeCelebritiesResponse> {
    const body: jsonP.JSONObject = {
      Image: fromImage(params["Image"]),
    };
    const resp = await this.#client.performRequest({
      abortSignal, body,
      action: "RecognizeCelebrities",
    });
    return jsonP.readObj({
      required: {},
      optional: {
        "CelebrityFaces": [toCelebrity],
        "UnrecognizedFaces": [toComparedFace],
        "OrientationCorrection": (x: jsonP.JSONValue) => cmnP.readEnum<OrientationCorrection>(x),
      },
    }, await resp.json());
  }

  async searchFaces(
    {abortSignal, ...params}: RequestConfig & SearchFacesRequest,
  ): Promise<SearchFacesResponse> {
    const body: jsonP.JSONObject = {
      CollectionId: params["CollectionId"],
      FaceId: params["FaceId"],
      MaxFaces: params["MaxFaces"],
      FaceMatchThreshold: params["FaceMatchThreshold"],
    };
    const resp = await this.#client.performRequest({
      abortSignal, body,
      action: "SearchFaces",
    });
    return jsonP.readObj({
      required: {},
      optional: {
        "SearchedFaceId": "s",
        "FaceMatches": [toFaceMatch],
        "FaceModelVersion": "s",
      },
    }, await resp.json());
  }

  async searchFacesByImage(
    {abortSignal, ...params}: RequestConfig & SearchFacesByImageRequest,
  ): Promise<SearchFacesByImageResponse> {
    const body: jsonP.JSONObject = {
      CollectionId: params["CollectionId"],
      Image: fromImage(params["Image"]),
      MaxFaces: params["MaxFaces"],
      FaceMatchThreshold: params["FaceMatchThreshold"],
      QualityFilter: params["QualityFilter"],
    };
    const resp = await this.#client.performRequest({
      abortSignal, body,
      action: "SearchFacesByImage",
    });
    return jsonP.readObj({
      required: {},
      optional: {
        "SearchedFaceBoundingBox": toBoundingBox,
        "SearchedFaceConfidence": "n",
        "FaceMatches": [toFaceMatch],
        "FaceModelVersion": "s",
      },
    }, await resp.json());
  }

  async startCelebrityRecognition(
    {abortSignal, ...params}: RequestConfig & StartCelebrityRecognitionRequest,
  ): Promise<StartCelebrityRecognitionResponse> {
    const body: jsonP.JSONObject = {
      Video: fromVideo(params["Video"]),
      ClientRequestToken: params["ClientRequestToken"],
      NotificationChannel: fromNotificationChannel(params["NotificationChannel"]),
      JobTag: params["JobTag"],
    };
    const resp = await this.#client.performRequest({
      abortSignal, body,
      action: "StartCelebrityRecognition",
    });
    return jsonP.readObj({
      required: {},
      optional: {
        "JobId": "s",
      },
    }, await resp.json());
  }

  async startContentModeration(
    {abortSignal, ...params}: RequestConfig & StartContentModerationRequest,
  ): Promise<StartContentModerationResponse> {
    const body: jsonP.JSONObject = {
      Video: fromVideo(params["Video"]),
      MinConfidence: params["MinConfidence"],
      ClientRequestToken: params["ClientRequestToken"],
      NotificationChannel: fromNotificationChannel(params["NotificationChannel"]),
      JobTag: params["JobTag"],
    };
    const resp = await this.#client.performRequest({
      abortSignal, body,
      action: "StartContentModeration",
    });
    return jsonP.readObj({
      required: {},
      optional: {
        "JobId": "s",
      },
    }, await resp.json());
  }

  async startFaceDetection(
    {abortSignal, ...params}: RequestConfig & StartFaceDetectionRequest,
  ): Promise<StartFaceDetectionResponse> {
    const body: jsonP.JSONObject = {
      Video: fromVideo(params["Video"]),
      ClientRequestToken: params["ClientRequestToken"],
      NotificationChannel: fromNotificationChannel(params["NotificationChannel"]),
      FaceAttributes: params["FaceAttributes"],
      JobTag: params["JobTag"],
    };
    const resp = await this.#client.performRequest({
      abortSignal, body,
      action: "StartFaceDetection",
    });
    return jsonP.readObj({
      required: {},
      optional: {
        "JobId": "s",
      },
    }, await resp.json());
  }

  async startFaceSearch(
    {abortSignal, ...params}: RequestConfig & StartFaceSearchRequest,
  ): Promise<StartFaceSearchResponse> {
    const body: jsonP.JSONObject = {
      Video: fromVideo(params["Video"]),
      ClientRequestToken: params["ClientRequestToken"],
      FaceMatchThreshold: params["FaceMatchThreshold"],
      CollectionId: params["CollectionId"],
      NotificationChannel: fromNotificationChannel(params["NotificationChannel"]),
      JobTag: params["JobTag"],
    };
    const resp = await this.#client.performRequest({
      abortSignal, body,
      action: "StartFaceSearch",
    });
    return jsonP.readObj({
      required: {},
      optional: {
        "JobId": "s",
      },
    }, await resp.json());
  }

  async startLabelDetection(
    {abortSignal, ...params}: RequestConfig & StartLabelDetectionRequest,
  ): Promise<StartLabelDetectionResponse> {
    const body: jsonP.JSONObject = {
      Video: fromVideo(params["Video"]),
      ClientRequestToken: params["ClientRequestToken"],
      MinConfidence: params["MinConfidence"],
      NotificationChannel: fromNotificationChannel(params["NotificationChannel"]),
      JobTag: params["JobTag"],
    };
    const resp = await this.#client.performRequest({
      abortSignal, body,
      action: "StartLabelDetection",
    });
    return jsonP.readObj({
      required: {},
      optional: {
        "JobId": "s",
      },
    }, await resp.json());
  }

  async startPersonTracking(
    {abortSignal, ...params}: RequestConfig & StartPersonTrackingRequest,
  ): Promise<StartPersonTrackingResponse> {
    const body: jsonP.JSONObject = {
      Video: fromVideo(params["Video"]),
      ClientRequestToken: params["ClientRequestToken"],
      NotificationChannel: fromNotificationChannel(params["NotificationChannel"]),
      JobTag: params["JobTag"],
    };
    const resp = await this.#client.performRequest({
      abortSignal, body,
      action: "StartPersonTracking",
    });
    return jsonP.readObj({
      required: {},
      optional: {
        "JobId": "s",
      },
    }, await resp.json());
  }

  async startProjectVersion(
    {abortSignal, ...params}: RequestConfig & StartProjectVersionRequest,
  ): Promise<StartProjectVersionResponse> {
    const body: jsonP.JSONObject = {
      ProjectVersionArn: params["ProjectVersionArn"],
      MinInferenceUnits: params["MinInferenceUnits"],
    };
    const resp = await this.#client.performRequest({
      abortSignal, body,
      action: "StartProjectVersion",
    });
    return jsonP.readObj({
      required: {},
      optional: {
        "Status": (x: jsonP.JSONValue) => cmnP.readEnum<ProjectVersionStatus>(x),
      },
    }, await resp.json());
  }

  async startSegmentDetection(
    {abortSignal, ...params}: RequestConfig & StartSegmentDetectionRequest,
  ): Promise<StartSegmentDetectionResponse> {
    const body: jsonP.JSONObject = {
      Video: fromVideo(params["Video"]),
      ClientRequestToken: params["ClientRequestToken"],
      NotificationChannel: fromNotificationChannel(params["NotificationChannel"]),
      JobTag: params["JobTag"],
      Filters: fromStartSegmentDetectionFilters(params["Filters"]),
      SegmentTypes: params["SegmentTypes"],
    };
    const resp = await this.#client.performRequest({
      abortSignal, body,
      action: "StartSegmentDetection",
    });
    return jsonP.readObj({
      required: {},
      optional: {
        "JobId": "s",
      },
    }, await resp.json());
  }

  async startStreamProcessor(
    {abortSignal, ...params}: RequestConfig & StartStreamProcessorRequest,
  ): Promise<StartStreamProcessorResponse> {
    const body: jsonP.JSONObject = {
      Name: params["Name"],
    };
    const resp = await this.#client.performRequest({
      abortSignal, body,
      action: "StartStreamProcessor",
    });
    return jsonP.readObj({
      required: {},
      optional: {},
    }, await resp.json());
  }

  async startTextDetection(
    {abortSignal, ...params}: RequestConfig & StartTextDetectionRequest,
  ): Promise<StartTextDetectionResponse> {
    const body: jsonP.JSONObject = {
      Video: fromVideo(params["Video"]),
      ClientRequestToken: params["ClientRequestToken"],
      NotificationChannel: fromNotificationChannel(params["NotificationChannel"]),
      JobTag: params["JobTag"],
      Filters: fromStartTextDetectionFilters(params["Filters"]),
    };
    const resp = await this.#client.performRequest({
      abortSignal, body,
      action: "StartTextDetection",
    });
    return jsonP.readObj({
      required: {},
      optional: {
        "JobId": "s",
      },
    }, await resp.json());
  }

  async stopProjectVersion(
    {abortSignal, ...params}: RequestConfig & StopProjectVersionRequest,
  ): Promise<StopProjectVersionResponse> {
    const body: jsonP.JSONObject = {
      ProjectVersionArn: params["ProjectVersionArn"],
    };
    const resp = await this.#client.performRequest({
      abortSignal, body,
      action: "StopProjectVersion",
    });
    return jsonP.readObj({
      required: {},
      optional: {
        "Status": (x: jsonP.JSONValue) => cmnP.readEnum<ProjectVersionStatus>(x),
      },
    }, await resp.json());
  }

  async stopStreamProcessor(
    {abortSignal, ...params}: RequestConfig & StopStreamProcessorRequest,
  ): Promise<StopStreamProcessorResponse> {
    const body: jsonP.JSONObject = {
      Name: params["Name"],
    };
    const resp = await this.#client.performRequest({
      abortSignal, body,
      action: "StopStreamProcessor",
    });
    return jsonP.readObj({
      required: {},
      optional: {},
    }, await resp.json());
  }

  // Resource State Waiters

  /**
   * Wait until the ProjectVersion training completes.
   * Checks state up to 360 times, 120 seconds apart (about 720 minutes max wait time).
   */
  async waitForProjectVersionTrainingCompleted(
    params: RequestConfig & DescribeProjectVersionsRequest,
  ): Promise<DescribeProjectVersionsResponse> {
    const errMessage = 'ResourceNotReady: Resource is not in the state ProjectVersionTrainingCompleted';
    for (let i = 0; i < 360; i++) {
      const resp = await this.describeProjectVersions(params);
      const field = resp?.ProjectVersionDescriptions?.flatMap(x => x?.Status);
      if (field?.every(x => x === "TRAINING_COMPLETED")) return resp;
      if (field?.some(x => x === "TRAINING_FAILED")) throw new Error(errMessage);
      await new Promise(r => setTimeout(r, 120000));
    }
    throw new Error(errMessage);
  }

  /**
   * Wait until the ProjectVersion is running.
   * Checks state up to 40 times, 30 seconds apart (about 20 minutes max wait time).
   */
  async waitForProjectVersionRunning(
    params: RequestConfig & DescribeProjectVersionsRequest,
  ): Promise<DescribeProjectVersionsResponse> {
    const errMessage = 'ResourceNotReady: Resource is not in the state ProjectVersionRunning';
    for (let i = 0; i < 40; i++) {
      const resp = await this.describeProjectVersions(params);
      const field = resp?.ProjectVersionDescriptions?.flatMap(x => x?.Status);
      if (field?.every(x => x === "RUNNING")) return resp;
      if (field?.some(x => x === "FAILED")) throw new Error(errMessage);
      await new Promise(r => setTimeout(r, 30000));
    }
    throw new Error(errMessage);
  }

}

// refs: 1 - tags: named, input
export interface CompareFacesRequest {
  SourceImage: Image;
  TargetImage: Image;
  SimilarityThreshold?: number | null;
  QualityFilter?: QualityFilter | null;
}

// refs: 1 - tags: named, input
export interface CreateCollectionRequest {
  CollectionId: string;
}

// refs: 1 - tags: named, input
export interface CreateProjectRequest {
  ProjectName: string;
}

// refs: 1 - tags: named, input
export interface CreateProjectVersionRequest {
  ProjectArn: string;
  VersionName: string;
  OutputConfig: OutputConfig;
  TrainingData: TrainingData;
  TestingData: TestingData;
}

// refs: 1 - tags: named, input
export interface CreateStreamProcessorRequest {
  Input: StreamProcessorInput;
  Output: StreamProcessorOutput;
  Name: string;
  Settings: StreamProcessorSettings;
  RoleArn: string;
}

// refs: 1 - tags: named, input
export interface DeleteCollectionRequest {
  CollectionId: string;
}

// refs: 1 - tags: named, input
export interface DeleteFacesRequest {
  CollectionId: string;
  FaceIds: string[];
}

// refs: 1 - tags: named, input
export interface DeleteProjectRequest {
  ProjectArn: string;
}

// refs: 1 - tags: named, input
export interface DeleteProjectVersionRequest {
  ProjectVersionArn: string;
}

// refs: 1 - tags: named, input
export interface DeleteStreamProcessorRequest {
  Name: string;
}

// refs: 1 - tags: named, input
export interface DescribeCollectionRequest {
  CollectionId: string;
}

// refs: 1 - tags: named, input
export interface DescribeProjectVersionsRequest {
  ProjectArn: string;
  VersionNames?: string[] | null;
  NextToken?: string | null;
  MaxResults?: number | null;
}

// refs: 1 - tags: named, input
export interface DescribeProjectsRequest {
  NextToken?: string | null;
  MaxResults?: number | null;
}

// refs: 1 - tags: named, input
export interface DescribeStreamProcessorRequest {
  Name: string;
}

// refs: 1 - tags: named, input
export interface DetectCustomLabelsRequest {
  ProjectVersionArn: string;
  Image: Image;
  MaxResults?: number | null;
  MinConfidence?: number | null;
}

// refs: 1 - tags: named, input
export interface DetectFacesRequest {
  Image: Image;
  Attributes?: Attribute[] | null;
}

// refs: 1 - tags: named, input
export interface DetectLabelsRequest {
  Image: Image;
  MaxLabels?: number | null;
  MinConfidence?: number | null;
}

// refs: 1 - tags: named, input
export interface DetectModerationLabelsRequest {
  Image: Image;
  MinConfidence?: number | null;
  HumanLoopConfig?: HumanLoopConfig | null;
}

// refs: 1 - tags: named, input
export interface DetectProtectiveEquipmentRequest {
  Image: Image;
  SummarizationAttributes?: ProtectiveEquipmentSummarizationAttributes | null;
}

// refs: 1 - tags: named, input
export interface DetectTextRequest {
  Image: Image;
  Filters?: DetectTextFilters | null;
}

// refs: 1 - tags: named, input
export interface GetCelebrityInfoRequest {
  Id: string;
}

// refs: 1 - tags: named, input
export interface GetCelebrityRecognitionRequest {
  JobId: string;
  MaxResults?: number | null;
  NextToken?: string | null;
  SortBy?: CelebrityRecognitionSortBy | null;
}

// refs: 1 - tags: named, input
export interface GetContentModerationRequest {
  JobId: string;
  MaxResults?: number | null;
  NextToken?: string | null;
  SortBy?: ContentModerationSortBy | null;
}

// refs: 1 - tags: named, input
export interface GetFaceDetectionRequest {
  JobId: string;
  MaxResults?: number | null;
  NextToken?: string | null;
}

// refs: 1 - tags: named, input
export interface GetFaceSearchRequest {
  JobId: string;
  MaxResults?: number | null;
  NextToken?: string | null;
  SortBy?: FaceSearchSortBy | null;
}

// refs: 1 - tags: named, input
export interface GetLabelDetectionRequest {
  JobId: string;
  MaxResults?: number | null;
  NextToken?: string | null;
  SortBy?: LabelDetectionSortBy | null;
}

// refs: 1 - tags: named, input
export interface GetPersonTrackingRequest {
  JobId: string;
  MaxResults?: number | null;
  NextToken?: string | null;
  SortBy?: PersonTrackingSortBy | null;
}

// refs: 1 - tags: named, input
export interface GetSegmentDetectionRequest {
  JobId: string;
  MaxResults?: number | null;
  NextToken?: string | null;
}

// refs: 1 - tags: named, input
export interface GetTextDetectionRequest {
  JobId: string;
  MaxResults?: number | null;
  NextToken?: string | null;
}

// refs: 1 - tags: named, input
export interface IndexFacesRequest {
  CollectionId: string;
  Image: Image;
  ExternalImageId?: string | null;
  DetectionAttributes?: Attribute[] | null;
  MaxFaces?: number | null;
  QualityFilter?: QualityFilter | null;
}

// refs: 1 - tags: named, input
export interface ListCollectionsRequest {
  NextToken?: string | null;
  MaxResults?: number | null;
}

// refs: 1 - tags: named, input
export interface ListFacesRequest {
  CollectionId: string;
  NextToken?: string | null;
  MaxResults?: number | null;
}

// refs: 1 - tags: named, input
export interface ListStreamProcessorsRequest {
  NextToken?: string | null;
  MaxResults?: number | null;
}

// refs: 1 - tags: named, input
export interface RecognizeCelebritiesRequest {
  Image: Image;
}

// refs: 1 - tags: named, input
export interface SearchFacesRequest {
  CollectionId: string;
  FaceId: string;
  MaxFaces?: number | null;
  FaceMatchThreshold?: number | null;
}

// refs: 1 - tags: named, input
export interface SearchFacesByImageRequest {
  CollectionId: string;
  Image: Image;
  MaxFaces?: number | null;
  FaceMatchThreshold?: number | null;
  QualityFilter?: QualityFilter | null;
}

// refs: 1 - tags: named, input
export interface StartCelebrityRecognitionRequest {
  Video: Video;
  ClientRequestToken?: string | null;
  NotificationChannel?: NotificationChannel | null;
  JobTag?: string | null;
}

// refs: 1 - tags: named, input
export interface StartContentModerationRequest {
  Video: Video;
  MinConfidence?: number | null;
  ClientRequestToken?: string | null;
  NotificationChannel?: NotificationChannel | null;
  JobTag?: string | null;
}

// refs: 1 - tags: named, input
export interface StartFaceDetectionRequest {
  Video: Video;
  ClientRequestToken?: string | null;
  NotificationChannel?: NotificationChannel | null;
  FaceAttributes?: FaceAttributes | null;
  JobTag?: string | null;
}

// refs: 1 - tags: named, input
export interface StartFaceSearchRequest {
  Video: Video;
  ClientRequestToken?: string | null;
  FaceMatchThreshold?: number | null;
  CollectionId: string;
  NotificationChannel?: NotificationChannel | null;
  JobTag?: string | null;
}

// refs: 1 - tags: named, input
export interface StartLabelDetectionRequest {
  Video: Video;
  ClientRequestToken?: string | null;
  MinConfidence?: number | null;
  NotificationChannel?: NotificationChannel | null;
  JobTag?: string | null;
}

// refs: 1 - tags: named, input
export interface StartPersonTrackingRequest {
  Video: Video;
  ClientRequestToken?: string | null;
  NotificationChannel?: NotificationChannel | null;
  JobTag?: string | null;
}

// refs: 1 - tags: named, input
export interface StartProjectVersionRequest {
  ProjectVersionArn: string;
  MinInferenceUnits: number;
}

// refs: 1 - tags: named, input
export interface StartSegmentDetectionRequest {
  Video: Video;
  ClientRequestToken?: string | null;
  NotificationChannel?: NotificationChannel | null;
  JobTag?: string | null;
  Filters?: StartSegmentDetectionFilters | null;
  SegmentTypes: SegmentType[];
}

// refs: 1 - tags: named, input
export interface StartStreamProcessorRequest {
  Name: string;
}

// refs: 1 - tags: named, input
export interface StartTextDetectionRequest {
  Video: Video;
  ClientRequestToken?: string | null;
  NotificationChannel?: NotificationChannel | null;
  JobTag?: string | null;
  Filters?: StartTextDetectionFilters | null;
}

// refs: 1 - tags: named, input
export interface StopProjectVersionRequest {
  ProjectVersionArn: string;
}

// refs: 1 - tags: named, input
export interface StopStreamProcessorRequest {
  Name: string;
}

// refs: 1 - tags: named, output
export interface CompareFacesResponse {
  SourceImageFace?: ComparedSourceImageFace | null;
  FaceMatches?: CompareFacesMatch[] | null;
  UnmatchedFaces?: ComparedFace[] | null;
  SourceImageOrientationCorrection?: OrientationCorrection | null;
  TargetImageOrientationCorrection?: OrientationCorrection | null;
}

// refs: 1 - tags: named, output
export interface CreateCollectionResponse {
  StatusCode?: number | null;
  CollectionArn?: string | null;
  FaceModelVersion?: string | null;
}

// refs: 1 - tags: named, output
export interface CreateProjectResponse {
  ProjectArn?: string | null;
}

// refs: 1 - tags: named, output
export interface CreateProjectVersionResponse {
  ProjectVersionArn?: string | null;
}

// refs: 1 - tags: named, output
export interface CreateStreamProcessorResponse {
  StreamProcessorArn?: string | null;
}

// refs: 1 - tags: named, output
export interface DeleteCollectionResponse {
  StatusCode?: number | null;
}

// refs: 1 - tags: named, output
export interface DeleteFacesResponse {
  DeletedFaces?: string[] | null;
}

// refs: 1 - tags: named, output
export interface DeleteProjectResponse {
  Status?: ProjectStatus | null;
}

// refs: 1 - tags: named, output
export interface DeleteProjectVersionResponse {
  Status?: ProjectVersionStatus | null;
}

// refs: 1 - tags: named, output
export interface DeleteStreamProcessorResponse {
}

// refs: 1 - tags: named, output
export interface DescribeCollectionResponse {
  FaceCount?: number | null;
  FaceModelVersion?: string | null;
  CollectionARN?: string | null;
  CreationTimestamp?: Date | number | null;
}

// refs: 1 - tags: named, output
export interface DescribeProjectVersionsResponse {
  ProjectVersionDescriptions?: ProjectVersionDescription[] | null;
  NextToken?: string | null;
}

// refs: 1 - tags: named, output
export interface DescribeProjectsResponse {
  ProjectDescriptions?: ProjectDescription[] | null;
  NextToken?: string | null;
}

// refs: 1 - tags: named, output
export interface DescribeStreamProcessorResponse {
  Name?: string | null;
  StreamProcessorArn?: string | null;
  Status?: StreamProcessorStatus | null;
  StatusMessage?: string | null;
  CreationTimestamp?: Date | number | null;
  LastUpdateTimestamp?: Date | number | null;
  Input?: StreamProcessorInput | null;
  Output?: StreamProcessorOutput | null;
  RoleArn?: string | null;
  Settings?: StreamProcessorSettings | null;
}

// refs: 1 - tags: named, output
export interface DetectCustomLabelsResponse {
  CustomLabels?: CustomLabel[] | null;
}

// refs: 1 - tags: named, output
export interface DetectFacesResponse {
  FaceDetails?: FaceDetail[] | null;
  OrientationCorrection?: OrientationCorrection | null;
}

// refs: 1 - tags: named, output
export interface DetectLabelsResponse {
  Labels?: Label[] | null;
  OrientationCorrection?: OrientationCorrection | null;
  LabelModelVersion?: string | null;
}

// refs: 1 - tags: named, output
export interface DetectModerationLabelsResponse {
  ModerationLabels?: ModerationLabel[] | null;
  ModerationModelVersion?: string | null;
  HumanLoopActivationOutput?: HumanLoopActivationOutput | null;
}

// refs: 1 - tags: named, output
export interface DetectProtectiveEquipmentResponse {
  ProtectiveEquipmentModelVersion?: string | null;
  Persons?: ProtectiveEquipmentPerson[] | null;
  Summary?: ProtectiveEquipmentSummary | null;
}

// refs: 1 - tags: named, output
export interface DetectTextResponse {
  TextDetections?: TextDetection[] | null;
  TextModelVersion?: string | null;
}

// refs: 1 - tags: named, output
export interface GetCelebrityInfoResponse {
  Urls?: string[] | null;
  Name?: string | null;
}

// refs: 1 - tags: named, output
export interface GetCelebrityRecognitionResponse {
  JobStatus?: VideoJobStatus | null;
  StatusMessage?: string | null;
  VideoMetadata?: VideoMetadata | null;
  NextToken?: string | null;
  Celebrities?: CelebrityRecognition[] | null;
}

// refs: 1 - tags: named, output
export interface GetContentModerationResponse {
  JobStatus?: VideoJobStatus | null;
  StatusMessage?: string | null;
  VideoMetadata?: VideoMetadata | null;
  ModerationLabels?: ContentModerationDetection[] | null;
  NextToken?: string | null;
  ModerationModelVersion?: string | null;
}

// refs: 1 - tags: named, output
export interface GetFaceDetectionResponse {
  JobStatus?: VideoJobStatus | null;
  StatusMessage?: string | null;
  VideoMetadata?: VideoMetadata | null;
  NextToken?: string | null;
  Faces?: FaceDetection[] | null;
}

// refs: 1 - tags: named, output
export interface GetFaceSearchResponse {
  JobStatus?: VideoJobStatus | null;
  StatusMessage?: string | null;
  NextToken?: string | null;
  VideoMetadata?: VideoMetadata | null;
  Persons?: PersonMatch[] | null;
}

// refs: 1 - tags: named, output
export interface GetLabelDetectionResponse {
  JobStatus?: VideoJobStatus | null;
  StatusMessage?: string | null;
  VideoMetadata?: VideoMetadata | null;
  NextToken?: string | null;
  Labels?: LabelDetection[] | null;
  LabelModelVersion?: string | null;
}

// refs: 1 - tags: named, output
export interface GetPersonTrackingResponse {
  JobStatus?: VideoJobStatus | null;
  StatusMessage?: string | null;
  VideoMetadata?: VideoMetadata | null;
  NextToken?: string | null;
  Persons?: PersonDetection[] | null;
}

// refs: 1 - tags: named, output
export interface GetSegmentDetectionResponse {
  JobStatus?: VideoJobStatus | null;
  StatusMessage?: string | null;
  VideoMetadata?: VideoMetadata[] | null;
  AudioMetadata?: AudioMetadata[] | null;
  NextToken?: string | null;
  Segments?: SegmentDetection[] | null;
  SelectedSegmentTypes?: SegmentTypeInfo[] | null;
}

// refs: 1 - tags: named, output
export interface GetTextDetectionResponse {
  JobStatus?: VideoJobStatus | null;
  StatusMessage?: string | null;
  VideoMetadata?: VideoMetadata | null;
  TextDetections?: TextDetectionResult[] | null;
  NextToken?: string | null;
  TextModelVersion?: string | null;
}

// refs: 1 - tags: named, output
export interface IndexFacesResponse {
  FaceRecords?: FaceRecord[] | null;
  OrientationCorrection?: OrientationCorrection | null;
  FaceModelVersion?: string | null;
  UnindexedFaces?: UnindexedFace[] | null;
}

// refs: 1 - tags: named, output
export interface ListCollectionsResponse {
  CollectionIds?: string[] | null;
  NextToken?: string | null;
  FaceModelVersions?: string[] | null;
}

// refs: 1 - tags: named, output
export interface ListFacesResponse {
  Faces?: Face[] | null;
  NextToken?: string | null;
  FaceModelVersion?: string | null;
}

// refs: 1 - tags: named, output
export interface ListStreamProcessorsResponse {
  NextToken?: string | null;
  StreamProcessors?: StreamProcessor[] | null;
}

// refs: 1 - tags: named, output
export interface RecognizeCelebritiesResponse {
  CelebrityFaces?: Celebrity[] | null;
  UnrecognizedFaces?: ComparedFace[] | null;
  OrientationCorrection?: OrientationCorrection | null;
}

// refs: 1 - tags: named, output
export interface SearchFacesResponse {
  SearchedFaceId?: string | null;
  FaceMatches?: FaceMatch[] | null;
  FaceModelVersion?: string | null;
}

// refs: 1 - tags: named, output
export interface SearchFacesByImageResponse {
  SearchedFaceBoundingBox?: BoundingBox | null;
  SearchedFaceConfidence?: number | null;
  FaceMatches?: FaceMatch[] | null;
  FaceModelVersion?: string | null;
}

// refs: 1 - tags: named, output
export interface StartCelebrityRecognitionResponse {
  JobId?: string | null;
}

// refs: 1 - tags: named, output
export interface StartContentModerationResponse {
  JobId?: string | null;
}

// refs: 1 - tags: named, output
export interface StartFaceDetectionResponse {
  JobId?: string | null;
}

// refs: 1 - tags: named, output
export interface StartFaceSearchResponse {
  JobId?: string | null;
}

// refs: 1 - tags: named, output
export interface StartLabelDetectionResponse {
  JobId?: string | null;
}

// refs: 1 - tags: named, output
export interface StartPersonTrackingResponse {
  JobId?: string | null;
}

// refs: 1 - tags: named, output
export interface StartProjectVersionResponse {
  Status?: ProjectVersionStatus | null;
}

// refs: 1 - tags: named, output
export interface StartSegmentDetectionResponse {
  JobId?: string | null;
}

// refs: 1 - tags: named, output
export interface StartStreamProcessorResponse {
}

// refs: 1 - tags: named, output
export interface StartTextDetectionResponse {
  JobId?: string | null;
}

// refs: 1 - tags: named, output
export interface StopProjectVersionResponse {
  Status?: ProjectVersionStatus | null;
}

// refs: 1 - tags: named, output
export interface StopStreamProcessorResponse {
}

// refs: 11 - tags: input, named, interface
export interface Image {
  Bytes?: Uint8Array | string | null;
  S3Object?: S3Object | null;
}
function fromImage(input?: Image | null): jsonP.JSONValue {
  if (!input) return input;
  return {
    Bytes: jsonP.serializeBlob(input["Bytes"]),
    S3Object: fromS3Object(input["S3Object"]),
  }
}

// refs: 29 - tags: input, named, interface, output
export interface S3Object {
  Bucket?: string | null;
  Name?: string | null;
  Version?: string | null;
}
function fromS3Object(input?: S3Object | null): jsonP.JSONValue {
  if (!input) return input;
  return {
    Bucket: input["Bucket"],
    Name: input["Name"],
    Version: input["Version"],
  }
}
function toS3Object(root: jsonP.JSONValue): S3Object {
  return jsonP.readObj({
    required: {},
    optional: {
      "Bucket": "s",
      "Name": "s",
      "Version": "s",
    },
  }, root);
}

// refs: 3 - tags: input, named, enum
export type QualityFilter =
| "NONE"
| "AUTO"
| "LOW"
| "MEDIUM"
| "HIGH"
| cmnP.UnexpectedEnumValue;

// refs: 2 - tags: input, named, interface, output
export interface OutputConfig {
  S3Bucket?: string | null;
  S3KeyPrefix?: string | null;
}
function fromOutputConfig(input?: OutputConfig | null): jsonP.JSONValue {
  if (!input) return input;
  return {
    S3Bucket: input["S3Bucket"],
    S3KeyPrefix: input["S3KeyPrefix"],
  }
}
function toOutputConfig(root: jsonP.JSONValue): OutputConfig {
  return jsonP.readObj({
    required: {},
    optional: {
      "S3Bucket": "s",
      "S3KeyPrefix": "s",
    },
  }, root);
}

// refs: 3 - tags: input, named, interface, output
export interface TrainingData {
  Assets?: Asset[] | null;
}
function fromTrainingData(input?: TrainingData | null): jsonP.JSONValue {
  if (!input) return input;
  return {
    Assets: input["Assets"]?.map(x => fromAsset(x)),
  }
}
function toTrainingData(root: jsonP.JSONValue): TrainingData {
  return jsonP.readObj({
    required: {},
    optional: {
      "Assets": [toAsset],
    },
  }, root);
}

// refs: 8 - tags: input, named, interface, output
export interface Asset {
  GroundTruthManifest?: GroundTruthManifest | null;
}
function fromAsset(input?: Asset | null): jsonP.JSONValue {
  if (!input) return input;
  return {
    GroundTruthManifest: fromGroundTruthManifest(input["GroundTruthManifest"]),
  }
}
function toAsset(root: jsonP.JSONValue): Asset {
  return jsonP.readObj({
    required: {},
    optional: {
      "GroundTruthManifest": toGroundTruthManifest,
    },
  }, root);
}

// refs: 9 - tags: input, named, interface, output
export interface GroundTruthManifest {
  S3Object?: S3Object | null;
}
function fromGroundTruthManifest(input?: GroundTruthManifest | null): jsonP.JSONValue {
  if (!input) return input;
  return {
    S3Object: fromS3Object(input["S3Object"]),
  }
}
function toGroundTruthManifest(root: jsonP.JSONValue): GroundTruthManifest {
  return jsonP.readObj({
    required: {},
    optional: {
      "S3Object": toS3Object,
    },
  }, root);
}

// refs: 3 - tags: input, named, interface, output
export interface TestingData {
  Assets?: Asset[] | null;
  AutoCreate?: boolean | null;
}
function fromTestingData(input?: TestingData | null): jsonP.JSONValue {
  if (!input) return input;
  return {
    Assets: input["Assets"]?.map(x => fromAsset(x)),
    AutoCreate: input["AutoCreate"],
  }
}
function toTestingData(root: jsonP.JSONValue): TestingData {
  return jsonP.readObj({
    required: {},
    optional: {
      "Assets": [toAsset],
      "AutoCreate": "b",
    },
  }, root);
}

// refs: 2 - tags: input, named, interface, output
export interface StreamProcessorInput {
  KinesisVideoStream?: KinesisVideoStream | null;
}
function fromStreamProcessorInput(input?: StreamProcessorInput | null): jsonP.JSONValue {
  if (!input) return input;
  return {
    KinesisVideoStream: fromKinesisVideoStream(input["KinesisVideoStream"]),
  }
}
function toStreamProcessorInput(root: jsonP.JSONValue): StreamProcessorInput {
  return jsonP.readObj({
    required: {},
    optional: {
      "KinesisVideoStream": toKinesisVideoStream,
    },
  }, root);
}

// refs: 2 - tags: input, named, interface, output
export interface KinesisVideoStream {
  Arn?: string | null;
}
function fromKinesisVideoStream(input?: KinesisVideoStream | null): jsonP.JSONValue {
  if (!input) return input;
  return {
    Arn: input["Arn"],
  }
}
function toKinesisVideoStream(root: jsonP.JSONValue): KinesisVideoStream {
  return jsonP.readObj({
    required: {},
    optional: {
      "Arn": "s",
    },
  }, root);
}

// refs: 2 - tags: input, named, interface, output
export interface StreamProcessorOutput {
  KinesisDataStream?: KinesisDataStream | null;
}
function fromStreamProcessorOutput(input?: StreamProcessorOutput | null): jsonP.JSONValue {
  if (!input) return input;
  return {
    KinesisDataStream: fromKinesisDataStream(input["KinesisDataStream"]),
  }
}
function toStreamProcessorOutput(root: jsonP.JSONValue): StreamProcessorOutput {
  return jsonP.readObj({
    required: {},
    optional: {
      "KinesisDataStream": toKinesisDataStream,
    },
  }, root);
}

// refs: 2 - tags: input, named, interface, output
export interface KinesisDataStream {
  Arn?: string | null;
}
function fromKinesisDataStream(input?: KinesisDataStream | null): jsonP.JSONValue {
  if (!input) return input;
  return {
    Arn: input["Arn"],
  }
}
function toKinesisDataStream(root: jsonP.JSONValue): KinesisDataStream {
  return jsonP.readObj({
    required: {},
    optional: {
      "Arn": "s",
    },
  }, root);
}

// refs: 2 - tags: input, named, interface, output
export interface StreamProcessorSettings {
  FaceSearch?: FaceSearchSettings | null;
}
function fromStreamProcessorSettings(input?: StreamProcessorSettings | null): jsonP.JSONValue {
  if (!input) return input;
  return {
    FaceSearch: fromFaceSearchSettings(input["FaceSearch"]),
  }
}
function toStreamProcessorSettings(root: jsonP.JSONValue): StreamProcessorSettings {
  return jsonP.readObj({
    required: {},
    optional: {
      "FaceSearch": toFaceSearchSettings,
    },
  }, root);
}

// refs: 2 - tags: input, named, interface, output
export interface FaceSearchSettings {
  CollectionId?: string | null;
  FaceMatchThreshold?: number | null;
}
function fromFaceSearchSettings(input?: FaceSearchSettings | null): jsonP.JSONValue {
  if (!input) return input;
  return {
    CollectionId: input["CollectionId"],
    FaceMatchThreshold: input["FaceMatchThreshold"],
  }
}
function toFaceSearchSettings(root: jsonP.JSONValue): FaceSearchSettings {
  return jsonP.readObj({
    required: {},
    optional: {
      "CollectionId": "s",
      "FaceMatchThreshold": "n",
    },
  }, root);
}

// refs: 2 - tags: input, named, enum
export type Attribute =
| "DEFAULT"
| "ALL"
| cmnP.UnexpectedEnumValue;

// refs: 1 - tags: input, named, interface
export interface HumanLoopConfig {
  HumanLoopName: string;
  FlowDefinitionArn: string;
  DataAttributes?: HumanLoopDataAttributes | null;
}
function fromHumanLoopConfig(input?: HumanLoopConfig | null): jsonP.JSONValue {
  if (!input) return input;
  return {
    HumanLoopName: input["HumanLoopName"],
    FlowDefinitionArn: input["FlowDefinitionArn"],
    DataAttributes: fromHumanLoopDataAttributes(input["DataAttributes"]),
  }
}

// refs: 1 - tags: input, named, interface
export interface HumanLoopDataAttributes {
  ContentClassifiers?: ContentClassifier[] | null;
}
function fromHumanLoopDataAttributes(input?: HumanLoopDataAttributes | null): jsonP.JSONValue {
  if (!input) return input;
  return {
    ContentClassifiers: input["ContentClassifiers"],
  }
}

// refs: 1 - tags: input, named, enum
export type ContentClassifier =
| "FreeOfPersonallyIdentifiableInformation"
| "FreeOfAdultContent"
| cmnP.UnexpectedEnumValue;

// refs: 1 - tags: input, named, interface
export interface ProtectiveEquipmentSummarizationAttributes {
  MinConfidence: number;
  RequiredEquipmentTypes: ProtectiveEquipmentType[];
}
function fromProtectiveEquipmentSummarizationAttributes(input?: ProtectiveEquipmentSummarizationAttributes | null): jsonP.JSONValue {
  if (!input) return input;
  return {
    MinConfidence: input["MinConfidence"],
    RequiredEquipmentTypes: input["RequiredEquipmentTypes"],
  }
}

// refs: 2 - tags: input, named, enum, output
export type ProtectiveEquipmentType =
| "FACE_COVER"
| "HAND_COVER"
| "HEAD_COVER"
| cmnP.UnexpectedEnumValue;

// refs: 1 - tags: input, named, interface
export interface DetectTextFilters {
  WordFilter?: DetectionFilter | null;
  RegionsOfInterest?: RegionOfInterest[] | null;
}
function fromDetectTextFilters(input?: DetectTextFilters | null): jsonP.JSONValue {
  if (!input) return input;
  return {
    WordFilter: fromDetectionFilter(input["WordFilter"]),
    RegionsOfInterest: input["RegionsOfInterest"]?.map(x => fromRegionOfInterest(x)),
  }
}

// refs: 2 - tags: input, named, interface
export interface DetectionFilter {
  MinConfidence?: number | null;
  MinBoundingBoxHeight?: number | null;
  MinBoundingBoxWidth?: number | null;
}
function fromDetectionFilter(input?: DetectionFilter | null): jsonP.JSONValue {
  if (!input) return input;
  return {
    MinConfidence: input["MinConfidence"],
    MinBoundingBoxHeight: input["MinBoundingBoxHeight"],
    MinBoundingBoxWidth: input["MinBoundingBoxWidth"],
  }
}

// refs: 2 - tags: input, named, interface
export interface RegionOfInterest {
  BoundingBox?: BoundingBox | null;
}
function fromRegionOfInterest(input?: RegionOfInterest | null): jsonP.JSONValue {
  if (!input) return input;
  return {
    BoundingBox: fromBoundingBox(input["BoundingBox"]),
  }
}

// refs: 30 - tags: input, named, interface, output
export interface BoundingBox {
  Width?: number | null;
  Height?: number | null;
  Left?: number | null;
  Top?: number | null;
}
function fromBoundingBox(input?: BoundingBox | null): jsonP.JSONValue {
  if (!input) return input;
  return {
    Width: input["Width"],
    Height: input["Height"],
    Left: input["Left"],
    Top: input["Top"],
  }
}
function toBoundingBox(root: jsonP.JSONValue): BoundingBox {
  return jsonP.readObj({
    required: {},
    optional: {
      "Width": "n",
      "Height": "n",
      "Left": "n",
      "Top": "n",
    },
  }, root);
}

// refs: 1 - tags: input, named, enum
export type CelebrityRecognitionSortBy =
| "ID"
| "TIMESTAMP"
| cmnP.UnexpectedEnumValue;

// refs: 1 - tags: input, named, enum
export type ContentModerationSortBy =
| "NAME"
| "TIMESTAMP"
| cmnP.UnexpectedEnumValue;

// refs: 1 - tags: input, named, enum
export type FaceSearchSortBy =
| "INDEX"
| "TIMESTAMP"
| cmnP.UnexpectedEnumValue;

// refs: 1 - tags: input, named, enum
export type LabelDetectionSortBy =
| "NAME"
| "TIMESTAMP"
| cmnP.UnexpectedEnumValue;

// refs: 1 - tags: input, named, enum
export type PersonTrackingSortBy =
| "INDEX"
| "TIMESTAMP"
| cmnP.UnexpectedEnumValue;

// refs: 8 - tags: input, named, interface
export interface Video {
  S3Object?: S3Object | null;
}
function fromVideo(input?: Video | null): jsonP.JSONValue {
  if (!input) return input;
  return {
    S3Object: fromS3Object(input["S3Object"]),
  }
}

// refs: 8 - tags: input, named, interface
export interface NotificationChannel {
  SNSTopicArn: string;
  RoleArn: string;
}
function fromNotificationChannel(input?: NotificationChannel | null): jsonP.JSONValue {
  if (!input) return input;
  return {
    SNSTopicArn: input["SNSTopicArn"],
    RoleArn: input["RoleArn"],
  }
}

// refs: 1 - tags: input, named, enum
export type FaceAttributes =
| "DEFAULT"
| "ALL"
| cmnP.UnexpectedEnumValue;

// refs: 1 - tags: input, named, interface
export interface StartSegmentDetectionFilters {
  TechnicalCueFilter?: StartTechnicalCueDetectionFilter | null;
  ShotFilter?: StartShotDetectionFilter | null;
}
function fromStartSegmentDetectionFilters(input?: StartSegmentDetectionFilters | null): jsonP.JSONValue {
  if (!input) return input;
  return {
    TechnicalCueFilter: fromStartTechnicalCueDetectionFilter(input["TechnicalCueFilter"]),
    ShotFilter: fromStartShotDetectionFilter(input["ShotFilter"]),
  }
}

// refs: 1 - tags: input, named, interface
export interface StartTechnicalCueDetectionFilter {
  MinSegmentConfidence?: number | null;
}
function fromStartTechnicalCueDetectionFilter(input?: StartTechnicalCueDetectionFilter | null): jsonP.JSONValue {
  if (!input) return input;
  return {
    MinSegmentConfidence: input["MinSegmentConfidence"],
  }
}

// refs: 1 - tags: input, named, interface
export interface StartShotDetectionFilter {
  MinSegmentConfidence?: number | null;
}
function fromStartShotDetectionFilter(input?: StartShotDetectionFilter | null): jsonP.JSONValue {
  if (!input) return input;
  return {
    MinSegmentConfidence: input["MinSegmentConfidence"],
  }
}

// refs: 3 - tags: input, named, enum, output
export type SegmentType =
| "TECHNICAL_CUE"
| "SHOT"
| cmnP.UnexpectedEnumValue;

// refs: 1 - tags: input, named, interface
export interface StartTextDetectionFilters {
  WordFilter?: DetectionFilter | null;
  RegionsOfInterest?: RegionOfInterest[] | null;
}
function fromStartTextDetectionFilters(input?: StartTextDetectionFilters | null): jsonP.JSONValue {
  if (!input) return input;
  return {
    WordFilter: fromDetectionFilter(input["WordFilter"]),
    RegionsOfInterest: input["RegionsOfInterest"]?.map(x => fromRegionOfInterest(x)),
  }
}

// refs: 1 - tags: output, named, interface
export interface ComparedSourceImageFace {
  BoundingBox?: BoundingBox | null;
  Confidence?: number | null;
}
function toComparedSourceImageFace(root: jsonP.JSONValue): ComparedSourceImageFace {
  return jsonP.readObj({
    required: {},
    optional: {
      "BoundingBox": toBoundingBox,
      "Confidence": "n",
    },
  }, root);
}

// refs: 1 - tags: output, named, interface
export interface CompareFacesMatch {
  Similarity?: number | null;
  Face?: ComparedFace | null;
}
function toCompareFacesMatch(root: jsonP.JSONValue): CompareFacesMatch {
  return jsonP.readObj({
    required: {},
    optional: {
      "Similarity": "n",
      "Face": toComparedFace,
    },
  }, root);
}

// refs: 4 - tags: output, named, interface
export interface ComparedFace {
  BoundingBox?: BoundingBox | null;
  Confidence?: number | null;
  Landmarks?: Landmark[] | null;
  Pose?: Pose | null;
  Quality?: ImageQuality | null;
}
function toComparedFace(root: jsonP.JSONValue): ComparedFace {
  return jsonP.readObj({
    required: {},
    optional: {
      "BoundingBox": toBoundingBox,
      "Confidence": "n",
      "Landmarks": [toLandmark],
      "Pose": toPose,
      "Quality": toImageQuality,
    },
  }, root);
}

// refs: 11 - tags: output, named, interface
export interface Landmark {
  Type?: LandmarkType | null;
  X?: number | null;
  Y?: number | null;
}
function toLandmark(root: jsonP.JSONValue): Landmark {
  return jsonP.readObj({
    required: {},
    optional: {
      "Type": (x: jsonP.JSONValue) => cmnP.readEnum<LandmarkType>(x),
      "X": "n",
      "Y": "n",
    },
  }, root);
}

// refs: 11 - tags: output, named, enum
export type LandmarkType =
| "eyeLeft"
| "eyeRight"
| "nose"
| "mouthLeft"
| "mouthRight"
| "leftEyeBrowLeft"
| "leftEyeBrowRight"
| "leftEyeBrowUp"
| "rightEyeBrowLeft"
| "rightEyeBrowRight"
| "rightEyeBrowUp"
| "leftEyeLeft"
| "leftEyeRight"
| "leftEyeUp"
| "leftEyeDown"
| "rightEyeLeft"
| "rightEyeRight"
| "rightEyeUp"
| "rightEyeDown"
| "noseLeft"
| "noseRight"
| "mouthUp"
| "mouthDown"
| "leftPupil"
| "rightPupil"
| "upperJawlineLeft"
| "midJawlineLeft"
| "chinBottom"
| "midJawlineRight"
| "upperJawlineRight"
| cmnP.UnexpectedEnumValue;

// refs: 11 - tags: output, named, interface
export interface Pose {
  Roll?: number | null;
  Yaw?: number | null;
  Pitch?: number | null;
}
function toPose(root: jsonP.JSONValue): Pose {
  return jsonP.readObj({
    required: {},
    optional: {
      "Roll": "n",
      "Yaw": "n",
      "Pitch": "n",
    },
  }, root);
}

// refs: 11 - tags: output, named, interface
export interface ImageQuality {
  Brightness?: number | null;
  Sharpness?: number | null;
}
function toImageQuality(root: jsonP.JSONValue): ImageQuality {
  return jsonP.readObj({
    required: {},
    optional: {
      "Brightness": "n",
      "Sharpness": "n",
    },
  }, root);
}

// refs: 6 - tags: output, named, enum
export type OrientationCorrection =
| "ROTATE_0"
| "ROTATE_90"
| "ROTATE_180"
| "ROTATE_270"
| cmnP.UnexpectedEnumValue;

// refs: 2 - tags: output, named, enum
export type ProjectStatus =
| "CREATING"
| "CREATED"
| "DELETING"
| cmnP.UnexpectedEnumValue;

// refs: 4 - tags: output, named, enum
export type ProjectVersionStatus =
| "TRAINING_IN_PROGRESS"
| "TRAINING_COMPLETED"
| "TRAINING_FAILED"
| "STARTING"
| "RUNNING"
| "FAILED"
| "STOPPING"
| "STOPPED"
| "DELETING"
| cmnP.UnexpectedEnumValue;

// refs: 1 - tags: output, named, interface
export interface ProjectVersionDescription {
  ProjectVersionArn?: string | null;
  CreationTimestamp?: Date | number | null;
  MinInferenceUnits?: number | null;
  Status?: ProjectVersionStatus | null;
  StatusMessage?: string | null;
  BillableTrainingTimeInSeconds?: number | null;
  TrainingEndTimestamp?: Date | number | null;
  OutputConfig?: OutputConfig | null;
  TrainingDataResult?: TrainingDataResult | null;
  TestingDataResult?: TestingDataResult | null;
  EvaluationResult?: EvaluationResult | null;
  ManifestSummary?: GroundTruthManifest | null;
}
function toProjectVersionDescription(root: jsonP.JSONValue): ProjectVersionDescription {
  return jsonP.readObj({
    required: {},
    optional: {
      "ProjectVersionArn": "s",
      "CreationTimestamp": "d",
      "MinInferenceUnits": "n",
      "Status": (x: jsonP.JSONValue) => cmnP.readEnum<ProjectVersionStatus>(x),
      "StatusMessage": "s",
      "BillableTrainingTimeInSeconds": "n",
      "TrainingEndTimestamp": "d",
      "OutputConfig": toOutputConfig,
      "TrainingDataResult": toTrainingDataResult,
      "TestingDataResult": toTestingDataResult,
      "EvaluationResult": toEvaluationResult,
      "ManifestSummary": toGroundTruthManifest,
    },
  }, root);
}

// refs: 1 - tags: output, named, interface
export interface TrainingDataResult {
  Input?: TrainingData | null;
  Output?: TrainingData | null;
  Validation?: ValidationData | null;
}
function toTrainingDataResult(root: jsonP.JSONValue): TrainingDataResult {
  return jsonP.readObj({
    required: {},
    optional: {
      "Input": toTrainingData,
      "Output": toTrainingData,
      "Validation": toValidationData,
    },
  }, root);
}

// refs: 2 - tags: output, named, interface
export interface ValidationData {
  Assets?: Asset[] | null;
}
function toValidationData(root: jsonP.JSONValue): ValidationData {
  return jsonP.readObj({
    required: {},
    optional: {
      "Assets": [toAsset],
    },
  }, root);
}

// refs: 1 - tags: output, named, interface
export interface TestingDataResult {
  Input?: TestingData | null;
  Output?: TestingData | null;
  Validation?: ValidationData | null;
}
function toTestingDataResult(root: jsonP.JSONValue): TestingDataResult {
  return jsonP.readObj({
    required: {},
    optional: {
      "Input": toTestingData,
      "Output": toTestingData,
      "Validation": toValidationData,
    },
  }, root);
}

// refs: 1 - tags: output, named, interface
export interface EvaluationResult {
  F1Score?: number | null;
  Summary?: Summary | null;
}
function toEvaluationResult(root: jsonP.JSONValue): EvaluationResult {
  return jsonP.readObj({
    required: {},
    optional: {
      "F1Score": "n",
      "Summary": toSummary,
    },
  }, root);
}

// refs: 1 - tags: output, named, interface
export interface Summary {
  S3Object?: S3Object | null;
}
function toSummary(root: jsonP.JSONValue): Summary {
  return jsonP.readObj({
    required: {},
    optional: {
      "S3Object": toS3Object,
    },
  }, root);
}

// refs: 1 - tags: output, named, interface
export interface ProjectDescription {
  ProjectArn?: string | null;
  CreationTimestamp?: Date | number | null;
  Status?: ProjectStatus | null;
}
function toProjectDescription(root: jsonP.JSONValue): ProjectDescription {
  return jsonP.readObj({
    required: {},
    optional: {
      "ProjectArn": "s",
      "CreationTimestamp": "d",
      "Status": (x: jsonP.JSONValue) => cmnP.readEnum<ProjectStatus>(x),
    },
  }, root);
}

// refs: 2 - tags: output, named, enum
export type StreamProcessorStatus =
| "STOPPED"
| "STARTING"
| "RUNNING"
| "FAILED"
| "STOPPING"
| cmnP.UnexpectedEnumValue;

// refs: 1 - tags: output, named, interface
export interface CustomLabel {
  Name?: string | null;
  Confidence?: number | null;
  Geometry?: Geometry | null;
}
function toCustomLabel(root: jsonP.JSONValue): CustomLabel {
  return jsonP.readObj({
    required: {},
    optional: {
      "Name": "s",
      "Confidence": "n",
      "Geometry": toGeometry,
    },
  }, root);
}

// refs: 3 - tags: output, named, interface
export interface Geometry {
  BoundingBox?: BoundingBox | null;
  Polygon?: Point[] | null;
}
function toGeometry(root: jsonP.JSONValue): Geometry {
  return jsonP.readObj({
    required: {},
    optional: {
      "BoundingBox": toBoundingBox,
      "Polygon": [toPoint],
    },
  }, root);
}

// refs: 3 - tags: output, named, interface
export interface Point {
  X?: number | null;
  Y?: number | null;
}
function toPoint(root: jsonP.JSONValue): Point {
  return jsonP.readObj({
    required: {},
    optional: {
      "X": "n",
      "Y": "n",
    },
  }, root);
}

// refs: 7 - tags: output, named, interface
export interface FaceDetail {
  BoundingBox?: BoundingBox | null;
  AgeRange?: AgeRange | null;
  Smile?: Smile | null;
  Eyeglasses?: Eyeglasses | null;
  Sunglasses?: Sunglasses | null;
  Gender?: Gender | null;
  Beard?: Beard | null;
  Mustache?: Mustache | null;
  EyesOpen?: EyeOpen | null;
  MouthOpen?: MouthOpen | null;
  Emotions?: Emotion[] | null;
  Landmarks?: Landmark[] | null;
  Pose?: Pose | null;
  Quality?: ImageQuality | null;
  Confidence?: number | null;
}
function toFaceDetail(root: jsonP.JSONValue): FaceDetail {
  return jsonP.readObj({
    required: {},
    optional: {
      "BoundingBox": toBoundingBox,
      "AgeRange": toAgeRange,
      "Smile": toSmile,
      "Eyeglasses": toEyeglasses,
      "Sunglasses": toSunglasses,
      "Gender": toGender,
      "Beard": toBeard,
      "Mustache": toMustache,
      "EyesOpen": toEyeOpen,
      "MouthOpen": toMouthOpen,
      "Emotions": [toEmotion],
      "Landmarks": [toLandmark],
      "Pose": toPose,
      "Quality": toImageQuality,
      "Confidence": "n",
    },
  }, root);
}

// refs: 7 - tags: output, named, interface
export interface AgeRange {
  Low?: number | null;
  High?: number | null;
}
function toAgeRange(root: jsonP.JSONValue): AgeRange {
  return jsonP.readObj({
    required: {},
    optional: {
      "Low": "n",
      "High": "n",
    },
  }, root);
}

// refs: 7 - tags: output, named, interface
export interface Smile {
  Value?: boolean | null;
  Confidence?: number | null;
}
function toSmile(root: jsonP.JSONValue): Smile {
  return jsonP.readObj({
    required: {},
    optional: {
      "Value": "b",
      "Confidence": "n",
    },
  }, root);
}

// refs: 7 - tags: output, named, interface
export interface Eyeglasses {
  Value?: boolean | null;
  Confidence?: number | null;
}
function toEyeglasses(root: jsonP.JSONValue): Eyeglasses {
  return jsonP.readObj({
    required: {},
    optional: {
      "Value": "b",
      "Confidence": "n",
    },
  }, root);
}

// refs: 7 - tags: output, named, interface
export interface Sunglasses {
  Value?: boolean | null;
  Confidence?: number | null;
}
function toSunglasses(root: jsonP.JSONValue): Sunglasses {
  return jsonP.readObj({
    required: {},
    optional: {
      "Value": "b",
      "Confidence": "n",
    },
  }, root);
}

// refs: 7 - tags: output, named, interface
export interface Gender {
  Value?: GenderType | null;
  Confidence?: number | null;
}
function toGender(root: jsonP.JSONValue): Gender {
  return jsonP.readObj({
    required: {},
    optional: {
      "Value": (x: jsonP.JSONValue) => cmnP.readEnum<GenderType>(x),
      "Confidence": "n",
    },
  }, root);
}

// refs: 7 - tags: output, named, enum
export type GenderType =
| "Male"
| "Female"
| cmnP.UnexpectedEnumValue;

// refs: 7 - tags: output, named, interface
export interface Beard {
  Value?: boolean | null;
  Confidence?: number | null;
}
function toBeard(root: jsonP.JSONValue): Beard {
  return jsonP.readObj({
    required: {},
    optional: {
      "Value": "b",
      "Confidence": "n",
    },
  }, root);
}

// refs: 7 - tags: output, named, interface
export interface Mustache {
  Value?: boolean | null;
  Confidence?: number | null;
}
function toMustache(root: jsonP.JSONValue): Mustache {
  return jsonP.readObj({
    required: {},
    optional: {
      "Value": "b",
      "Confidence": "n",
    },
  }, root);
}

// refs: 7 - tags: output, named, interface
export interface EyeOpen {
  Value?: boolean | null;
  Confidence?: number | null;
}
function toEyeOpen(root: jsonP.JSONValue): EyeOpen {
  return jsonP.readObj({
    required: {},
    optional: {
      "Value": "b",
      "Confidence": "n",
    },
  }, root);
}

// refs: 7 - tags: output, named, interface
export interface MouthOpen {
  Value?: boolean | null;
  Confidence?: number | null;
}
function toMouthOpen(root: jsonP.JSONValue): MouthOpen {
  return jsonP.readObj({
    required: {},
    optional: {
      "Value": "b",
      "Confidence": "n",
    },
  }, root);
}

// refs: 7 - tags: output, named, interface
export interface Emotion {
  Type?: EmotionName | null;
  Confidence?: number | null;
}
function toEmotion(root: jsonP.JSONValue): Emotion {
  return jsonP.readObj({
    required: {},
    optional: {
      "Type": (x: jsonP.JSONValue) => cmnP.readEnum<EmotionName>(x),
      "Confidence": "n",
    },
  }, root);
}

// refs: 7 - tags: output, named, enum
export type EmotionName =
| "HAPPY"
| "SAD"
| "ANGRY"
| "CONFUSED"
| "DISGUSTED"
| "SURPRISED"
| "CALM"
| "UNKNOWN"
| "FEAR"
| cmnP.UnexpectedEnumValue;

// refs: 2 - tags: output, named, interface
export interface Label {
  Name?: string | null;
  Confidence?: number | null;
  Instances?: Instance[] | null;
  Parents?: Parent[] | null;
}
function toLabel(root: jsonP.JSONValue): Label {
  return jsonP.readObj({
    required: {},
    optional: {
      "Name": "s",
      "Confidence": "n",
      "Instances": [toInstance],
      "Parents": [toParent],
    },
  }, root);
}

// refs: 2 - tags: output, named, interface
export interface Instance {
  BoundingBox?: BoundingBox | null;
  Confidence?: number | null;
}
function toInstance(root: jsonP.JSONValue): Instance {
  return jsonP.readObj({
    required: {},
    optional: {
      "BoundingBox": toBoundingBox,
      "Confidence": "n",
    },
  }, root);
}

// refs: 2 - tags: output, named, interface
export interface Parent {
  Name?: string | null;
}
function toParent(root: jsonP.JSONValue): Parent {
  return jsonP.readObj({
    required: {},
    optional: {
      "Name": "s",
    },
  }, root);
}

// refs: 2 - tags: output, named, interface
export interface ModerationLabel {
  Confidence?: number | null;
  Name?: string | null;
  ParentName?: string | null;
}
function toModerationLabel(root: jsonP.JSONValue): ModerationLabel {
  return jsonP.readObj({
    required: {},
    optional: {
      "Confidence": "n",
      "Name": "s",
      "ParentName": "s",
    },
  }, root);
}

// refs: 1 - tags: output, named, interface
export interface HumanLoopActivationOutput {
  HumanLoopArn?: string | null;
  HumanLoopActivationReasons?: string[] | null;
  HumanLoopActivationConditionsEvaluationResults?: jsonP.JSONValue | null;
}
function toHumanLoopActivationOutput(root: jsonP.JSONValue): HumanLoopActivationOutput {
  return jsonP.readObj({
    required: {},
    optional: {
      "HumanLoopArn": "s",
      "HumanLoopActivationReasons": ["s"],
      "HumanLoopActivationConditionsEvaluationResults": jsonP.readJsonValue,
    },
  }, root);
}

// refs: 1 - tags: output, named, interface
export interface ProtectiveEquipmentPerson {
  BodyParts?: ProtectiveEquipmentBodyPart[] | null;
  BoundingBox?: BoundingBox | null;
  Confidence?: number | null;
  Id?: number | null;
}
function toProtectiveEquipmentPerson(root: jsonP.JSONValue): ProtectiveEquipmentPerson {
  return jsonP.readObj({
    required: {},
    optional: {
      "BodyParts": [toProtectiveEquipmentBodyPart],
      "BoundingBox": toBoundingBox,
      "Confidence": "n",
      "Id": "n",
    },
  }, root);
}

// refs: 1 - tags: output, named, interface
export interface ProtectiveEquipmentBodyPart {
  Name?: BodyPart | null;
  Confidence?: number | null;
  EquipmentDetections?: EquipmentDetection[] | null;
}
function toProtectiveEquipmentBodyPart(root: jsonP.JSONValue): ProtectiveEquipmentBodyPart {
  return jsonP.readObj({
    required: {},
    optional: {
      "Name": (x: jsonP.JSONValue) => cmnP.readEnum<BodyPart>(x),
      "Confidence": "n",
      "EquipmentDetections": [toEquipmentDetection],
    },
  }, root);
}

// refs: 1 - tags: output, named, enum
export type BodyPart =
| "FACE"
| "HEAD"
| "LEFT_HAND"
| "RIGHT_HAND"
| cmnP.UnexpectedEnumValue;

// refs: 1 - tags: output, named, interface
export interface EquipmentDetection {
  BoundingBox?: BoundingBox | null;
  Confidence?: number | null;
  Type?: ProtectiveEquipmentType | null;
  CoversBodyPart?: CoversBodyPart | null;
}
function toEquipmentDetection(root: jsonP.JSONValue): EquipmentDetection {
  return jsonP.readObj({
    required: {},
    optional: {
      "BoundingBox": toBoundingBox,
      "Confidence": "n",
      "Type": (x: jsonP.JSONValue) => cmnP.readEnum<ProtectiveEquipmentType>(x),
      "CoversBodyPart": toCoversBodyPart,
    },
  }, root);
}

// refs: 1 - tags: output, named, interface
export interface CoversBodyPart {
  Confidence?: number | null;
  Value?: boolean | null;
}
function toCoversBodyPart(root: jsonP.JSONValue): CoversBodyPart {
  return jsonP.readObj({
    required: {},
    optional: {
      "Confidence": "n",
      "Value": "b",
    },
  }, root);
}

// refs: 1 - tags: output, named, interface
export interface ProtectiveEquipmentSummary {
  PersonsWithRequiredEquipment?: number[] | null;
  PersonsWithoutRequiredEquipment?: number[] | null;
  PersonsIndeterminate?: number[] | null;
}
function toProtectiveEquipmentSummary(root: jsonP.JSONValue): ProtectiveEquipmentSummary {
  return jsonP.readObj({
    required: {},
    optional: {
      "PersonsWithRequiredEquipment": ["n"],
      "PersonsWithoutRequiredEquipment": ["n"],
      "PersonsIndeterminate": ["n"],
    },
  }, root);
}

// refs: 2 - tags: output, named, interface
export interface TextDetection {
  DetectedText?: string | null;
  Type?: TextTypes | null;
  Id?: number | null;
  ParentId?: number | null;
  Confidence?: number | null;
  Geometry?: Geometry | null;
}
function toTextDetection(root: jsonP.JSONValue): TextDetection {
  return jsonP.readObj({
    required: {},
    optional: {
      "DetectedText": "s",
      "Type": (x: jsonP.JSONValue) => cmnP.readEnum<TextTypes>(x),
      "Id": "n",
      "ParentId": "n",
      "Confidence": "n",
      "Geometry": toGeometry,
    },
  }, root);
}

// refs: 2 - tags: output, named, enum
export type TextTypes =
| "LINE"
| "WORD"
| cmnP.UnexpectedEnumValue;

// refs: 8 - tags: output, named, enum
export type VideoJobStatus =
| "IN_PROGRESS"
| "SUCCEEDED"
| "FAILED"
| cmnP.UnexpectedEnumValue;

// refs: 8 - tags: output, named, interface
export interface VideoMetadata {
  Codec?: string | null;
  DurationMillis?: number | null;
  Format?: string | null;
  FrameRate?: number | null;
  FrameHeight?: number | null;
  FrameWidth?: number | null;
}
function toVideoMetadata(root: jsonP.JSONValue): VideoMetadata {
  return jsonP.readObj({
    required: {},
    optional: {
      "Codec": "s",
      "DurationMillis": "n",
      "Format": "s",
      "FrameRate": "n",
      "FrameHeight": "n",
      "FrameWidth": "n",
    },
  }, root);
}

// refs: 1 - tags: output, named, interface
export interface CelebrityRecognition {
  Timestamp?: number | null;
  Celebrity?: CelebrityDetail | null;
}
function toCelebrityRecognition(root: jsonP.JSONValue): CelebrityRecognition {
  return jsonP.readObj({
    required: {},
    optional: {
      "Timestamp": "n",
      "Celebrity": toCelebrityDetail,
    },
  }, root);
}

// refs: 1 - tags: output, named, interface
export interface CelebrityDetail {
  Urls?: string[] | null;
  Name?: string | null;
  Id?: string | null;
  Confidence?: number | null;
  BoundingBox?: BoundingBox | null;
  Face?: FaceDetail | null;
}
function toCelebrityDetail(root: jsonP.JSONValue): CelebrityDetail {
  return jsonP.readObj({
    required: {},
    optional: {
      "Urls": ["s"],
      "Name": "s",
      "Id": "s",
      "Confidence": "n",
      "BoundingBox": toBoundingBox,
      "Face": toFaceDetail,
    },
  }, root);
}

// refs: 1 - tags: output, named, interface
export interface ContentModerationDetection {
  Timestamp?: number | null;
  ModerationLabel?: ModerationLabel | null;
}
function toContentModerationDetection(root: jsonP.JSONValue): ContentModerationDetection {
  return jsonP.readObj({
    required: {},
    optional: {
      "Timestamp": "n",
      "ModerationLabel": toModerationLabel,
    },
  }, root);
}

// refs: 1 - tags: output, named, interface
export interface FaceDetection {
  Timestamp?: number | null;
  Face?: FaceDetail | null;
}
function toFaceDetection(root: jsonP.JSONValue): FaceDetection {
  return jsonP.readObj({
    required: {},
    optional: {
      "Timestamp": "n",
      "Face": toFaceDetail,
    },
  }, root);
}

// refs: 1 - tags: output, named, interface
export interface PersonMatch {
  Timestamp?: number | null;
  Person?: PersonDetail | null;
  FaceMatches?: FaceMatch[] | null;
}
function toPersonMatch(root: jsonP.JSONValue): PersonMatch {
  return jsonP.readObj({
    required: {},
    optional: {
      "Timestamp": "n",
      "Person": toPersonDetail,
      "FaceMatches": [toFaceMatch],
    },
  }, root);
}

// refs: 2 - tags: output, named, interface
export interface PersonDetail {
  Index?: number | null;
  BoundingBox?: BoundingBox | null;
  Face?: FaceDetail | null;
}
function toPersonDetail(root: jsonP.JSONValue): PersonDetail {
  return jsonP.readObj({
    required: {},
    optional: {
      "Index": "n",
      "BoundingBox": toBoundingBox,
      "Face": toFaceDetail,
    },
  }, root);
}

// refs: 3 - tags: output, named, interface
export interface FaceMatch {
  Similarity?: number | null;
  Face?: Face | null;
}
function toFaceMatch(root: jsonP.JSONValue): FaceMatch {
  return jsonP.readObj({
    required: {},
    optional: {
      "Similarity": "n",
      "Face": toFace,
    },
  }, root);
}

// refs: 5 - tags: output, named, interface
export interface Face {
  FaceId?: string | null;
  BoundingBox?: BoundingBox | null;
  ImageId?: string | null;
  ExternalImageId?: string | null;
  Confidence?: number | null;
}
function toFace(root: jsonP.JSONValue): Face {
  return jsonP.readObj({
    required: {},
    optional: {
      "FaceId": "s",
      "BoundingBox": toBoundingBox,
      "ImageId": "s",
      "ExternalImageId": "s",
      "Confidence": "n",
    },
  }, root);
}

// refs: 1 - tags: output, named, interface
export interface LabelDetection {
  Timestamp?: number | null;
  Label?: Label | null;
}
function toLabelDetection(root: jsonP.JSONValue): LabelDetection {
  return jsonP.readObj({
    required: {},
    optional: {
      "Timestamp": "n",
      "Label": toLabel,
    },
  }, root);
}

// refs: 1 - tags: output, named, interface
export interface PersonDetection {
  Timestamp?: number | null;
  Person?: PersonDetail | null;
}
function toPersonDetection(root: jsonP.JSONValue): PersonDetection {
  return jsonP.readObj({
    required: {},
    optional: {
      "Timestamp": "n",
      "Person": toPersonDetail,
    },
  }, root);
}

// refs: 1 - tags: output, named, interface
export interface AudioMetadata {
  Codec?: string | null;
  DurationMillis?: number | null;
  SampleRate?: number | null;
  NumberOfChannels?: number | null;
}
function toAudioMetadata(root: jsonP.JSONValue): AudioMetadata {
  return jsonP.readObj({
    required: {},
    optional: {
      "Codec": "s",
      "DurationMillis": "n",
      "SampleRate": "n",
      "NumberOfChannels": "n",
    },
  }, root);
}

// refs: 1 - tags: output, named, interface
export interface SegmentDetection {
  Type?: SegmentType | null;
  StartTimestampMillis?: number | null;
  EndTimestampMillis?: number | null;
  DurationMillis?: number | null;
  StartTimecodeSMPTE?: string | null;
  EndTimecodeSMPTE?: string | null;
  DurationSMPTE?: string | null;
  TechnicalCueSegment?: TechnicalCueSegment | null;
  ShotSegment?: ShotSegment | null;
}
function toSegmentDetection(root: jsonP.JSONValue): SegmentDetection {
  return jsonP.readObj({
    required: {},
    optional: {
      "Type": (x: jsonP.JSONValue) => cmnP.readEnum<SegmentType>(x),
      "StartTimestampMillis": "n",
      "EndTimestampMillis": "n",
      "DurationMillis": "n",
      "StartTimecodeSMPTE": "s",
      "EndTimecodeSMPTE": "s",
      "DurationSMPTE": "s",
      "TechnicalCueSegment": toTechnicalCueSegment,
      "ShotSegment": toShotSegment,
    },
  }, root);
}

// refs: 1 - tags: output, named, interface
export interface TechnicalCueSegment {
  Type?: TechnicalCueType | null;
  Confidence?: number | null;
}
function toTechnicalCueSegment(root: jsonP.JSONValue): TechnicalCueSegment {
  return jsonP.readObj({
    required: {},
    optional: {
      "Type": (x: jsonP.JSONValue) => cmnP.readEnum<TechnicalCueType>(x),
      "Confidence": "n",
    },
  }, root);
}

// refs: 1 - tags: output, named, enum
export type TechnicalCueType =
| "ColorBars"
| "EndCredits"
| "BlackFrames"
| cmnP.UnexpectedEnumValue;

// refs: 1 - tags: output, named, interface
export interface ShotSegment {
  Index?: number | null;
  Confidence?: number | null;
}
function toShotSegment(root: jsonP.JSONValue): ShotSegment {
  return jsonP.readObj({
    required: {},
    optional: {
      "Index": "n",
      "Confidence": "n",
    },
  }, root);
}

// refs: 1 - tags: output, named, interface
export interface SegmentTypeInfo {
  Type?: SegmentType | null;
  ModelVersion?: string | null;
}
function toSegmentTypeInfo(root: jsonP.JSONValue): SegmentTypeInfo {
  return jsonP.readObj({
    required: {},
    optional: {
      "Type": (x: jsonP.JSONValue) => cmnP.readEnum<SegmentType>(x),
      "ModelVersion": "s",
    },
  }, root);
}

// refs: 1 - tags: output, named, interface
export interface TextDetectionResult {
  Timestamp?: number | null;
  TextDetection?: TextDetection | null;
}
function toTextDetectionResult(root: jsonP.JSONValue): TextDetectionResult {
  return jsonP.readObj({
    required: {},
    optional: {
      "Timestamp": "n",
      "TextDetection": toTextDetection,
    },
  }, root);
}

// refs: 1 - tags: output, named, interface
export interface FaceRecord {
  Face?: Face | null;
  FaceDetail?: FaceDetail | null;
}
function toFaceRecord(root: jsonP.JSONValue): FaceRecord {
  return jsonP.readObj({
    required: {},
    optional: {
      "Face": toFace,
      "FaceDetail": toFaceDetail,
    },
  }, root);
}

// refs: 1 - tags: output, named, interface
export interface UnindexedFace {
  Reasons?: Reason[] | null;
  FaceDetail?: FaceDetail | null;
}
function toUnindexedFace(root: jsonP.JSONValue): UnindexedFace {
  return jsonP.readObj({
    required: {},
    optional: {
      "Reasons": [(x: jsonP.JSONValue) => cmnP.readEnum<Reason>(x)],
      "FaceDetail": toFaceDetail,
    },
  }, root);
}

// refs: 1 - tags: output, named, enum
export type Reason =
| "EXCEEDS_MAX_FACES"
| "EXTREME_POSE"
| "LOW_BRIGHTNESS"
| "LOW_SHARPNESS"
| "LOW_CONFIDENCE"
| "SMALL_BOUNDING_BOX"
| "LOW_FACE_QUALITY"
| cmnP.UnexpectedEnumValue;

// refs: 1 - tags: output, named, interface
export interface StreamProcessor {
  Name?: string | null;
  Status?: StreamProcessorStatus | null;
}
function toStreamProcessor(root: jsonP.JSONValue): StreamProcessor {
  return jsonP.readObj({
    required: {},
    optional: {
      "Name": "s",
      "Status": (x: jsonP.JSONValue) => cmnP.readEnum<StreamProcessorStatus>(x),
    },
  }, root);
}

// refs: 1 - tags: output, named, interface
export interface Celebrity {
  Urls?: string[] | null;
  Name?: string | null;
  Id?: string | null;
  Face?: ComparedFace | null;
  MatchConfidence?: number | null;
}
function toCelebrity(root: jsonP.JSONValue): Celebrity {
  return jsonP.readObj({
    required: {},
    optional: {
      "Urls": ["s"],
      "Name": "s",
      "Id": "s",
      "Face": toComparedFace,
      "MatchConfidence": "n",
    },
  }, root);
}
